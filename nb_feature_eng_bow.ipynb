{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Feature Engineering: bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "#from sklearn.base import TransformerMixin\n",
    "#from sklearn.pipeline import Pipeline\n",
    "#from sklearn.svm import LinearSVC\n",
    "#from sklearn.linear_model import SGDClassifier\n",
    "#from sklearn.metrics import accuracy_score\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.multiclass import OneVsRestClassifier\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "#from sklearn.metrics import classification_report\n",
    "#from gensim import corpora, models\n",
    "#from textblob import TextBlob\n",
    "#import operator\n",
    "#import mord\n",
    "\n",
    "from src import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "db_file = './data/db_master.pickle'\n",
    "df = pd.read_pickle(db_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Take a subset for testing\n",
    "df = df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 593 ms, sys: 10 ms, total: 603 ms\n",
      "Wall time: 635 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "src/text_preparation.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df['precleantext'][i] = clean_text\n",
      "src/text_preparation.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df['difftext'][i] = diff_text\n"
     ]
    }
   ],
   "source": [
    "# Pre-clean text\n",
    "% time df = pre_clean_text(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urn</th>\n",
       "      <th>name</th>\n",
       "      <th>url</th>\n",
       "      <th>ofsted</th>\n",
       "      <th>rawtext</th>\n",
       "      <th>scraping</th>\n",
       "      <th>precleantext</th>\n",
       "      <th>difftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100322</td>\n",
       "      <td>Avonmore Primary School</td>\n",
       "      <td>http://www.avonmore.lbhf.sch.uk/</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NOLINKABOUT</td>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100324</td>\n",
       "      <td>Brackenbury Primary School</td>\n",
       "      <td>http://www.brackenbury.lbhf.sch.uk/</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Video: A Day in the Life of Brackenbury, Prov...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Video: A Day in the Life of Brackenbury, Prov...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100326</td>\n",
       "      <td>Miles Coverdale Primary School</td>\n",
       "      <td>http://www.milescoverdaleprimary.co.uk/</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[We want every child to fulfil their potential...</td>\n",
       "      <td>1</td>\n",
       "      <td>[We want every child to fulfil their potential...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100328</td>\n",
       "      <td>Flora Gardens Primary School</td>\n",
       "      <td>http://www.floragardens.lbhf.sch.uk/</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[Flora Gardens Primary School, Dalling Road, H...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Flora Gardens Primary School, Dalling Road, H...</td>\n",
       "      <td>[Please click here to view our prospectus, Cur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100331</td>\n",
       "      <td>Kenmont Primary School</td>\n",
       "      <td>http://www.kenmont-primary.org/</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[Kenmont has three main community languages - ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Kenmont has three main community languages - ...</td>\n",
       "      <td>[World Book Day Thursday 2nd March 2017Februar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      urn                            name  \\\n",
       "0  100322         Avonmore Primary School   \n",
       "1  100324      Brackenbury Primary School   \n",
       "2  100326  Miles Coverdale Primary School   \n",
       "3  100328    Flora Gardens Primary School   \n",
       "4  100331          Kenmont Primary School   \n",
       "\n",
       "                                       url  ofsted  \\\n",
       "0         http://www.avonmore.lbhf.sch.uk/     2.0   \n",
       "1      http://www.brackenbury.lbhf.sch.uk/     1.0   \n",
       "2  http://www.milescoverdaleprimary.co.uk/     1.0   \n",
       "3     http://www.floragardens.lbhf.sch.uk/     3.0   \n",
       "4          http://www.kenmont-primary.org/     2.0   \n",
       "\n",
       "                                             rawtext  scraping  \\\n",
       "0                                        NOLINKABOUT        -1   \n",
       "1  [Video: A Day in the Life of Brackenbury, Prov...         1   \n",
       "2  [We want every child to fulfil their potential...         1   \n",
       "3  [Flora Gardens Primary School, Dalling Road, H...         1   \n",
       "4  [Kenmont has three main community languages - ...         1   \n",
       "\n",
       "                                        precleantext  \\\n",
       "0                                                      \n",
       "1  [Video: A Day in the Life of Brackenbury, Prov...   \n",
       "2  [We want every child to fulfil their potential...   \n",
       "3  [Flora Gardens Primary School, Dalling Road, H...   \n",
       "4  [Kenmont has three main community languages - ...   \n",
       "\n",
       "                                            difftext  \n",
       "0                                                     \n",
       "1                                                 []  \n",
       "2                                                 []  \n",
       "3  [Please click here to view our prospectus, Cur...  \n",
       "4  [World Book Day Thursday 2nd March 2017Februar...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "src/text_preparation.py:145: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df['tokens'][i] = tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.2 s, sys: 2.71 s, total: 16.9 s\n",
      "Wall time: 36.9 s\n"
     ]
    }
   ],
   "source": [
    "# Tokenize\n",
    "%time df = tokenize_text(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['urn', 'name', 'url', 'ofsted', 'rawtext', 'scraping',\n",
       "       'precleantext', 'difftext', 'tokens'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = df.drop(['scraping', 'difftext'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = df.drop(['url', 'rawtext'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['urn', 'name', 'ofsted', 'precleantext', 'tokens'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "db_file_clean = './data/db_master_clean.pickle'\n",
    "df.to_pickle(db_file_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Read data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "db_file = './data/db_master_clean.pickle'\n",
    "df = pd.read_pickle(db_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['urn', 'name', 'ofsted', 'cleantext', 'tokens'], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/site-packages/ipykernel/__main__.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Merge tokens to a single string\n",
    "\n",
    "for i in range(0,df.shape[0]):\n",
    "#for i in range(0,4):\n",
    "    tokens = df['tokens'][i]\n",
    "    text = ''\n",
    "    for j in range(0, len(tokens)):\n",
    "        if (j == 0):\n",
    "            text += ''.join(tokens[j])\n",
    "        else:\n",
    "            text += ''.join(' ' + tokens[j])\n",
    "    df['tokens'][i] = str(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1, 1), stop_words=None, min_df=0.0, max_df=1.0)\n",
    "X = vectorizer.fit_transform(df['tokens'])\n",
    "y = df['ofsted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 3, 0, ..., 1, 1, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [2, 0, 0, ..., 1, 0, 6],\n",
       "       [1, 1, 1, ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_features_bow(X, min_df=0.0, max_df=1.0):\n",
    "    \n",
    "    def print_feature_report(X_tfidf, min_df, max_df): \n",
    "        print \">>> feature report:\"\n",
    "        X_length, _ = X_tfidf[:,0].shape\n",
    "        print \"%d texts\" % X_length\n",
    "        print \"required minimal word occurence of %.1f\" % min_df\n",
    "        print \"required maximal word occurence of %.1f\" % max_df\n",
    "        print \"global number of different words in texts:\", X_tfidf.count_nonzero()\n",
    "    \n",
    "    ##### 1) Clean and Tokenize Text\n",
    "    # write first 4 web_scraped text in raw, cleaned and tokenized form\n",
    "    # to files './data/nlp/raw.txt', './data/nlp/cleaned.txt' and \n",
    "    # './data/nlp/tokenized.txt' for inspection \n",
    "    #write_example_text_to_file(X,'raw',4)\n",
    "    #write_example_text_to_file(X,'cleaned',4)\n",
    "    #write_example_text_to_file(X,'tokenized',4)\n",
    "    #print '>>> Raw text: \\n', X[0][:100]\n",
    "    #print '\\n>>> Cleaned text: \\n', cleanText(X[0])[:100]\n",
    "    #print '\\n>>> Cleaned and tokenized text (first 10 tokens): \\n', tokenizeText(cleanText(X[0]))[:10]\n",
    "\n",
    "    ##### 2) Feature Vectorization of Words (\"Bag of Words\")\n",
    "    # count_vectorizer = class that contains dictionary of vocabulary etc.\n",
    "    # X_counts = (sparse) feature matrix that counts the number of appearances in X\n",
    "    count_vectorizer, X_counts = initiate_count_vectorizer(X, min_df=min_df, max_df=max_df)\n",
    "    #print X_counts.count_nonzero()\n",
    "    #print X_counts.data[:4]\n",
    "\n",
    "    #### 3) Tf-Idf Transformation\n",
    "    tfidf_transformer, X_tfidf = initiate_tfidf_transformer(X_counts)\n",
    "    #print X_tfidf.count_nonzero()\n",
    "    #print X_tfidf.data[:4]\n",
    "    \n",
    "    print_feature_report(X_tfidf, min_df, max_df)\n",
    "    \n",
    "    return X_tfidf, X_counts, count_vectorizer, tfidf_transformer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python2",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
